{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMdBlujqfIsKMgDNIItn5ol"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 08-1 합성곱 신경망의 구성 요소\n"],"metadata":{"id":"5WESU22R32Wn"}},{"cell_type":"markdown","source":["##합성곱\n","\n","합성곱(convolution)은 마치 입력 데이터에 마법의 도장을 찍어서 유용한 특성만 드러나게 하는 것으로 비유할 수 있다.\n","\n","밀집층에는 뉴런마다 입력 개수만큼의 가중치가 존재. 즉 모든 입력에 가중치를 곱한다.\n","\n","인공 신경망은 처음에 가중치와 절편을 랜덤하게 초기화한 다음 에포크를 반복하면서 경사 하강법 알고리즘을 사용하여 손실이 낮아지도록 최적의 가중치와 절편을 찾아간다. 이것이 바로 모델훈련이다.\n","\n","예를 들면 밀집층에 뉴런이 3개 있다면 출력은 3개가 된다.\n","\n","합성곱은 밀집층의 계산과 조금 다르다. 입력 데이터 전테에 가중치를 적용하는 것이 아니라 일부에 가중치를 곱한다.\n","\n","밀집층의 뉴런은 입력 개수만큼 10개의 가중치를 가지고 1개의 출력은 만든다. 합성곱 층의 뉴런은 3개의 가중치를 가지고 8개의 출력을 만든다. 합성곱 층의 뉴런에 있는 가중치 개수는 정하기 나름이디. 즉 또 다른 하이퍼 파라미터이다. 이는 마치 입력 데이터 위를 이동하면서 같은 도장으로 하나씩 찍는 것처럼 생각할 수 있다. 도장을 찍을 때 마다 출력이 하나씩 만들어지는 것이다.\n","\n","<br><br><br>\n","\n","이전에 신경망 층은 뉴런이 길게 늘어서 있고 서로 조밀하게 연결되어 있었다. 그런데 합성곱에서는 뉴런이 입력 위를 이동하면서 출력을 만들기 때문에 이런 식으로 표현하기가 어렵다. 또 뉴런이라고 부르기도 어색하다.  합성곱 신경망 (convolutional neural network, CNN) 에서는 완전 연결 신경망과 달리 뉴런을 필터(filter)라고 부른다. 혹은 커널(kernel) 이라고도 부른다.\n","\n","\n","합성곱의 장점은 1차원이 아니라 2차원 입력에도 적용할 수 있다는 것이다.\n","\n","입력이 2차원 배열이면 필터도 2차원이어야 한다. 이 그림에서 이 필터는 커널 크기는(3,3)으로 가정. 그다음 왼쪽 위 모서리에서부터 합성곱을 시작한다. 입력의 9개 원소와 커널의 9개의 가중치를 곱한 후(여기에서도 절편을 더한다) 1개의 출력을 만든다.\n","\n","그다음에는 필터가 오른쪽으로 한 칸 이동하여 합성곱을 또 수행한다. 입력의 너비가 4이므로 더 이상 오른쪽으로 한 칸 이동할 수 없다. 이럴 때는 아래로 한 칸 이동한 다음 다시 왼쪽에서부터 합성곱을 수행한다. 그리고 다시 오른쪽으로 한 칸 이동한다.\n","<br><br><br>\n","합성곱은 마치 도장을 찍듯이 왼쪽 위에서 오른쪽 맨 아래까지 이동하면서 출력을 만든다. 계산식은 밀집층과 크게 다르지 않다. 입력과 가중치의 행과 열을 맞추어 곱셈하고 모두 더하는게 전부다.\n","\n","합성곱 계산을 통해 얻은 출력을 특별히 특성 맵(feature map)이라고 부른다.\n","\n","밀집층에서 여러 개의 뉴런을 사용하듯이 합성곱 층에서도 여러개의 필터를 사용한다. 여러 개의 필터를 사용하면 만들어진 특성 맵은 순서대로 차곡차곡 샇인다. (2,2) 크기의 특성 맵을 쌓으면 3차원 배열이 된다.\n","\n","<br><br>\n","\n","밀집층에 있는 뉴런의 가중치가 모두 다르듯이 합성곱 층에 있는 필터의 가중치 (커널)도 모두 다르다. 너무 당연하지만 같은 가중치를 가진 필터를 여러 개 사용할 이유가 없다.\n","\n","\n"],"metadata":{"id":"Q88SCl3I4KWs"}},{"cell_type":"markdown","source":["###케라스 합성곱 층\n","\n","케라스의 층은 모두 keras.layers 패키지 아래 클래스로 구현되어 있다. 합성곱 층도 마찬가지다. 특별히 입력 위를 이동하는 합성곱은 Conv2D 클래스로 제공한다."],"metadata":{"id":"PjobJDic877B"}},{"cell_type":"code","source":["from tensorflow import keras\n","\n","keras.layers.Conv2D(10, kernel_size = (3 , 3), activation = 'relu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0deA5EYf9KzX","executionInfo":{"status":"ok","timestamp":1710570788822,"user_tz":-540,"elapsed":5,"user":{"displayName":"박민호","userId":"13332700724784488473"}},"outputId":"530388fb-2477-4fb3-dbd7-1e15fb49b7ba"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.src.layers.convolutional.conv2d.Conv2D at 0x7f4ff9d27370>"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["Conv2D 클래스의 첫 번째 매개변수는 필터의 개수이다. kernel_size 매개변수는 필터에 사용할 커널의 크기를 지정한다. 필터의 개수와 커널의 크기는 반드시 지정해야 하는 매개변수다. 마지막으로 밀집층에서처럼 활성화 함수를 지정한다.\n","\n","케라스 API를 사용하면 합성곱 층을 사용하는 것이 어렵지 않다.\n","\n","합성곱 신경망의 정의는 일반적으로 1개 이상의 합성곱 층을 쓴 인공 신경망을 합성곱 신경망이라고 부른다.\n","\n","그런데 합성곱 신경망을 실제 만들려면 조금 더 알아야 할 것들이 있다. 바로 패딩과 스트라이드이다."],"metadata":{"id":"d8JXrIgd9ush"}},{"cell_type":"markdown","source":["### 패딩과 스트라이드\n","\n","(4 , 4) 크기의입력에 (3 , 3) 크기의 커널을 적용하여 (2 , 2)크기의 특성 맵을 만들었다. 그런데 만약 커널 크기는 (3 , 3)으로 그대로 두고 출력의 크기를 입력과 동일하게 (4 , 4) 만들려면 어떻게 해야할까?\n","\n","\n","\n","바로 입력 배열의 주위를 가상의 원소로 채우는 패딩(padding)을 실시한다. 실제 입력값이 아니기 때문에 패딩은 0으로 채운다. 즉 (4, 4) 크기의 입력에 0을 1개 패딩하면 (6, 6) 크기의 입력이 된다. 패딩의 역할은 순전히 커널이 도장을 찍을 횟수를 늘려주는 것밖에는 없다. 실제 값은 0으로 채워져 있기 때문에 계산에 영향을 미치지는 않는다.\n","<br>\n","\n","이렇게 입력과 특성 맴의 크기를 동일하게 만들기 위해 입력 주위에 0으로 패딩 하는 것을 세임 패딩(same padding)이라고 부른다. 합성곱 신경망에서는 세임 패딩이 많이 사용된다.\n","\n","<br>\n","\n","패딩 없이 순수한 입력 배열에서만 합성곱을 하여 특성 맵을 만드는 경우를 밸리드 패딩(valid padding)이라고 한다.\n","\n","그럼 왜 합성곱에서는 패딩을 즐겨 사용할까?\n","\n","만약 패딩이 없이 합성곱을 한다면 왼쪽 위 모서리의 값은 커널 도장에 딱 한 번만 찍힌다. 네 모서리에 있는 다른 3개의 값도 마찬가지다. 반면 다른 원소들은 2번 이상 커널과 계산된다.\n","\n","<br>\n","\n","적절한 패딩은 이처럼 이미지의 주변에 있는 정보를 잃어버리지 않도록 도와준다. 앞에서도 언급했지만 일반적인 합성곱 신경망에서는 세임 패딩이 많이 사용된다. 케라스 Conv2D 클래스에서 padding 매개변수로 패딩을 지정할 수 있다. 기본값은 'valid'로 밸리드 패딩을 나타낸다. 세임 패딩을 사용하려면 'same'으로 지정해야한다."],"metadata":{"id":"TTzMb65z-oLS"}},{"cell_type":"code","source":["keras.layers.Conv2D(10, kernel_size =(3, 3), activation = 'relu', padding = 'same')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2gffSqAoA-0T","executionInfo":{"status":"ok","timestamp":1710571688648,"user_tz":-540,"elapsed":308,"user":{"displayName":"박민호","userId":"13332700724784488473"}},"outputId":"baa87d59-9cd0-412f-c838-0854c52c435e"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.src.layers.convolutional.conv2d.Conv2D at 0x7f4ff8838730>"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["지금까지는 합성곱 연산은 좌우, 위아래로 한 칸씩 이동했다. 하지만 두 칸씩 건너뛸 수도 있다. 이렇게 두 칸씩 이동하면 만들어지는 특성 맵의 크기는 더 작아진다.\n","이런 이동의 크기를 스트라이드(stride)라고 한다. 기본으로 스트라이드는 1이다. 즉 한 칸씩 이동한다. 이 값이 케라스 Conv2D의 strides 매개변수의 기본값이다."],"metadata":{"id":"zB9gl1bsBZq3"}},{"cell_type":"code","source":["keras.layers.Conv2D(10, kernel_size = (3,3), activation = 'relu',\n","                    padding = 'same', strides = 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FrAlO6PwCP9G","executionInfo":{"status":"ok","timestamp":1710572033086,"user_tz":-540,"elapsed":3,"user":{"displayName":"박민호","userId":"13332700724784488473"}},"outputId":"cc3bb73d-a319-4431-cbd6-6652b0407853"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.src.layers.convolutional.conv2d.Conv2D at 0x7f4ff87f1c90>"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["strides 매개변수는 오른쪽으로 이동하는 크기와 아래쪽으로 이동하는 크기를 (1,1)과 같이 튜플을 사용해 각각 지정할 수 있다. 하지만 커널의 이동 크기를 가로세로 방향으로 다르게 지정하는 경우는 거의 없다. 또 1보다 큰 스트라이드를 사용하는 경우도 드물다. 대부분 기본값을 그대로 사용하기 때문에 strides 매개변수는 잘 사용하지 않는다.\n","\n","이제 합성곱 신경망의 마지막 구성 요소인 풀링으로 넘어가보자."],"metadata":{"id":"9WzQIpQ2CgdQ"}},{"cell_type":"markdown","source":["###풀링\n","\n","풀링(pooling)은 합성곱 층에서 만든 특성 맵의 가로세로 크기를 줄이는 역할을 수행한다. 하지만 특성 뱁의 개수는 줄이지 않는다.\n","\n","풀릳오 합성곱처럼 입력 위를 지나가면서 도장을 찍는다. 위 그림에서는(2, 2) 크기로 풀링을 한다. 하지만 풀링에는 가중치가 없다. 도장을 찍은 영역에서 가장 큰 값을 고르거나 평균값을 계산한다. 이를 각각 최대 풀링(max pooling)과 평균 풀링(average pooling)이라고 부른다. 풀링은 합성곱 층과 뚜렷이 구분되기 때문에 풀링 층이라고 부른다.\n","\n","(4, 4)크기의 특성 맵이 있다고 가정하고 여기에 (2, 2) 최대 풀링을 적용하면 절반으로 크기가 줄어든다.\n","\n","풀링 영역은 합성곱과 다르게 겹치지 않고 이동한다. 따라서 크기가(2, 2)이면 가로세로 두 칸씩 이동한다. 즉 스트라이드가 2가 된다.\n","\n","풀링은 가중치가 없고 풀링 크기와 스트라이드 크기가 같기 때문에 이해하기 쉽다. 또 패딩도 없다. 케라스에서는 MaxPooling2D 클래스로 풀링을 수행할 수 있다."],"metadata":{"id":"tLRWaaMUC3NM"}},{"cell_type":"code","source":["keras.layers.MaxPooling2D(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cNOtvjeJETiT","executionInfo":{"status":"ok","timestamp":1710572554907,"user_tz":-540,"elapsed":10,"user":{"displayName":"박민호","userId":"13332700724784488473"}},"outputId":"4fbc297d-ee5d-41b9-8fd3-764d7a323723"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.src.layers.pooling.max_pooling2d.MaxPooling2D at 0x7f4ff8734910>"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["평균 풀링을 제공하는 클래스는 AveragePooling2D이다. 최댓값 대신 평균을 계산하는 것만 빼먄 MaxPooling2D와 동일하며 제공하는 매개변수도 같다. 많은 경우 평균 풀링보다 최대 풀링을 많이 사용한다. 평균 풀링은 특성 맵에 있는 중요한 정보를 (평균하여) 회석시킬 수 있기 때문이다.\n","\n","<br>\n","\n","꼭 기억할 점은 풀링은 가로세로 방향으로만 진행한다. 특성 맵의 개수는 변하지 않고 그대로다."],"metadata":{"id":"p5U9kZPGES81"}},{"cell_type":"markdown","source":["## 합성곱 신경망의 전체구조"],"metadata":{"id":"Nf7SQx7SFIBm"}},{"cell_type":"markdown","source":["합성곱 층에서 사용할 커널의 크기는 (3, 3) 크기이고 세임 패딩이므로 1픽셀이 입력 데이터 주변에 추가되었다. 그다음 패딩이 추가된 입력에서 합성곱이 수행된다.\n","\n","따로 언급하지 않는 다면 합성곱의 스트라이드는 항상 1이다. 밀집층과 마찬가지로 합성곱 층에서도 활성화 함수를 적용한다. 합성곱 층은 활성화 함수로 렐루 함수를 많이 사용한다.\n","\n","그다음  풀링 층이다. 풀링 층은 합성곱 층에서 만든 특성 맵의 가로세로 크기를 줄인다.\n","\n","풀링을 사용하는 이유는 합성곱에서 스트라이드를 크게 하여 특성 맵을 줄이는 것보다 풀링 층에서 크기를 줄이는 것이 경협적으로 더 나은 성능을 내기 때문이다.\n","\n","합성곱 신경망은 이렇게 합성곱 층에서 특성 맵을 생성하고 풀링에서 크기를 줄이는 구조가 쌍을 이룬다.\n","\n","풀링을 거친 특성 맵의 크기는 절반으로 줄어든 3채원 배열이 되었다. 밀집층인 출력층에 전달하려면 이 3차원 배열을 1차원으로 펼쳐야 한다.\n","\n","출력층에는 3개의 뉴런을 두자. 즉 3개의 클래스를 분류하는 다중 분류 문제다. 출력층에서 계산된 값은 소프트맥스 활성화 함수를 거쳐 최종 예측 확률이 된다.\n"],"metadata":{"id":"5QRjlOPFFUl6"}},{"cell_type":"markdown","source":["### 컬러 이미지를 이용한 합성곱\n","\n","지금까지 우리는 입력을 2차원 배열이라고 가정했다.\n","\n","패션 MNIST 데이터는 실제로 흑백 이미지이기 때문에 2차원 배열로 표현할 수 있다. 컬러 이미지는 RGB 채널로 구성되어 있기 때문에 컴퓨터는 이를 3차원 배열로 표시한다.\n","\n","깊이가 있는 입력에서 합성곱을 수행하기 위해서는 도장도 깊이가 필요하다. 즉 필터의 커널 크기가 (3, 3)이 아니라 (3, 3, 3)이 된다.\n","\n","이 합성곱의 계산은 (3, 3, 3) 영역에 해당하는 27개의 원소에 27개의 가중치를 곱하고 절편을 더하는 식이 된다. 여기서 중요한 것은 입력이나 필터의 차원이 몇 개인지 상관없이 항상 출력은 하나의 값이라는 점이다. 즉 특성 맵에 있는 한 원소가 채워진다.\n","\n","케라스의 합성곱 층은 항상 이렇게 3차원 입력을 기대한다. 만약 패션 MNIST 데이터처럼 흑백 이미지일 경우에는 깊이 차원이 1인 3차원 배열로 변환하여 전달한다. 예를 들어(28, 28) 크기의 2차원 배열을 (28, 28, 1) 크기의 3차원 배열로 변환한다.\n","\n","이와 비슷한 경우로 합성곱 층-풀링 층 다음에 다시 또 합성곱 층이 올때이다. 이렇게 되면 합성곱 신경망은 너비와 높이는 점점 줄어들고 깊이는 점점 깊어지는 것이 특징이다. 그리고 마지막에 출력층 전에 특성 맵을 모두 펼쳐서 밀집층의 입력으로 사용한다."],"metadata":{"id":"bzrjRldWGxiP"}}]}